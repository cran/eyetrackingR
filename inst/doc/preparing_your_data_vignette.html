<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Overview of this vignette</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<blockquote>
<p><strong>Our Experiment</strong>: Each eyetrackingR vignette uses the <em>eyetrackingR</em> package to analyze real data from a simple 2-alternative forced choice (2AFC) word recognition task administered to 19- and 24-month-olds.
On each trial, infants were shown a picture of an animate object (e.g., a horse) and an inanimate object (e.g., a spoon). After inspecting the images, they disappeared and they heard a label referring to one of them (e.g., &ldquo;The horse is nearby!&rdquo;). Finally, the objects re-appeared on the screen and they were prompted to look at the target (e.g., &ldquo;Look at the horse!&rdquo;).</p>
</blockquote>

<h1>Overview of this vignette</h1>

<p>This vignette will cover the basics of preparing your data for use with eyetrackingR.</p>

<h2>Your Data</h2>

<p>eyetrackingR is designed to deal with data in a (relatively) raw form, where <strong>each row specifies a sample.</strong> Each row should represent an equally spaced unit of time (e.g., if your eye-tracker&#39;s sample rate is 100hz, then each row corresponds to the eye-position every 10ms). </p>

<p>This is in contrast to the more parsed data that the software bundled with eye-trackers can sometimes output (e.g., already parsed into saccades or fixations). For eyetrackingR, the simplest data is the best. </p>

<p>This also <strong>maximizes compatibility:</strong> eyetrackingR will work with any eye-tracker&#39;s data (e.g., Eyelink, Tobii, etc.), since it requires the most basic format.</p>

<p><strong>Note:</strong> eyetrackingR does not handle reading your data into R. Most software bundled with your eyetracker should be capable of exporting your data to a delimited format (.csv, tab-delimited .txt), etc. From there, you can use base functions like <code>read.delim</code>, or (recommended) check out the package <a href="https://cran.r-project.org/package=readr">readr</a>.</p>

<hr/>

<p>eyetrackingR just needs to the following columns:</p>

<ul>
<li><strong>Participant Columns:</strong> Specifies the unique code for each participant (e.g., &#39;SUBJ101&#39;)</li>
<li><strong>Trial Columns:</strong> Specifies the unique name or number of each trial. For experiments in which each subject sees each item only once, this can be either a name (e.g., &#39;HORSE-DOG&#39;) or a number (e.g., trial 1, 2, 3, etc.). But if trials see items multiple times, this will almost always be a number.</li>
<li><strong>Timestamp Column:</strong> Specifies the cumulative time passed within each trial (e.g., in milliseconds: 0, 50, 100, &hellip;, 1500). This column specifies the time-within-trial. If you have a timestamp column, but the beginning of the timestamp doesn&#39;t correspond to the beginning of the trial in the way you&#39;d like, the function <code>subset_by_window</code> can help fix this.</li>
<li><strong>AOI Column(s):</strong> (Note: If you don&#39;t have these columns, the function <code>add_aoi</code> can create them&ndash; see below.) These columns specify whether the gaze is in a particular &#39;Area of Interest.&#39; Each AOI should have a corresponding column. The elements of this column specify, for each sample, whether the participant&#39;s gaze was in that AOI.</li>
<li><strong>Trackloss Column:</strong> Specifies, for each sample, whether the eye-tracker lost the eyes for that sample. Helpful for cleaning data and removing unreliable trials. See <code>clean_by_trackloss</code> below.</li>
</ul>

<p>There are also some optional columns, which you might want to use depending on your analysis:</p>

<ul>
<li><strong>Item column(s):</strong> This corresponds to any &#39;items&#39; in your experiment: types of stimuli presented across trials. This is likely to always be a name (e.g., &#39;HORSE-DOG&#39;) and, unlike the &#39;Trial&#39; column, this does not need to be unique.</li>
<li><strong>Miscellaneous predictor column(s):</strong> These are columns specifying predictors (e.g., Condition, Age, Sex). Unlike the types above, these are specified separately for each analysis, not at the outset).</li>
</ul>

<p>If your dataset has these columns, you&#39;re ready to begin using eyetrackingR.</p>

<h1>Data Preparation</h1>

<h2>Load dataset and dependencies, set data options for eyetrackingR.</h2>

<p>Before being used in eyetrackingR, data must be run through the <code>make_eyetrackingr_data</code> function. </p>

<p>This lets you provide the information about your dataset that was just described above. The function will perform some checks on your data to make sure it&#39;s in the correct format.</p>

<p>For this dataset, because each participant saw each item only once in this experiment, <code>trial_column</code> specifies a unique name for each trial (e.g., &ldquo;FamiliarCow&rdquo;) and we don&#39;t specify an <code>item_column</code>.</p>

<pre><code class="r">set.seed(42)

library(&quot;Matrix&quot;)
library(&quot;lme4&quot;)
library(&quot;ggplot2&quot;)
library(&quot;eyetrackingR&quot;)

data(&quot;word_recognition&quot;)
data &lt;- make_eyetrackingr_data(word_recognition, 
                               participant_column = &quot;ParticipantName&quot;,
                               trial_column = &quot;Trial&quot;,
                               time_column = &quot;TimeFromTrialOnset&quot;,
                               trackloss_column = &quot;TrackLoss&quot;,
                               aoi_columns = c(&#39;Animate&#39;,&#39;Inanimate&#39;),
                               treat_non_aoi_looks_as_missing = TRUE
)
</code></pre>

<h3>Dealing with Non-AOI Looks</h3>

<p>You might be wondering about the <code>treat_non_aoi_looks_as_missing</code> argument above.</p>

<p>Almost all eyetracking analyses require calculating proportion looking&ndash;across a trial, within a time bin, etc. One important choice you as the researcher have to make is whether to include non-AOI looking in this calculation. There are two options:</p>

<ul>
<li><strong>Treat Non-AOI Looks as Missing Data.</strong> For many visual world paradigms, this move reflects the assumption that looking to a blank portion of the screen might as well be considered trackloss. The main advantage to this technique is that it makes analyses focusing on the tradeoff between two or more AOI more easily interpretable. Without treating outside looks as trackloss, it can be difficult to interpret an increase in looking to a single AOI across conditions. Was this due to an overall increase in attention (that is, looking to <em>all</em> AOIs, including the one of interest, increased)? Or due to an increase in preference for that AOI specifically? </li>
<li><strong>Treat Non-AOI Looks as Valid Data</strong> The tradeoff with the above is that, if we are interested in overall attention to all AOIs across conditions, then the previous approach will obscure this difference. So the alternative is to treat non-AOI looks as valid. </li>
</ul>

<p>The argument <code>treat_non_aoi_looks_as_missing</code> lets you decide which of these options eyetrackingR will do. If set to TRUE, when it comes time for eyetrackingR to calculate proportion looking to an AOI, this will be calculated as &ldquo;time looking to that AOI divided by time looking to all other AOIs.&rdquo; In contrast, if this parameter is set to FALSE, proportion looking to an AOI will be calculated as &ldquo;time looking to that AOI divided by total time looking (excluding actual trackloss).&rdquo;</p>

<h2>Cleaning Up Messy Data:</h2>

<p>We all wish our data came right out of our eye-tracker ready for analysis, but this isn&#39;t always the case. Two of the more annoying problems you might encounter are:</p>

<ul>
<li><p><strong>Your data doesn&#39;t have any columns corresponding to areas-of-interest.</strong> Maybe you needed to create or revise these after running the experiment, or your eyetracking software just doesn&#39;t let you specify them.</p></li>
<li><p><strong>Your data doesn&#39;t specify when the relevant things in a trial start.</strong> Experiments are complicated. There are pre-phases, fixation-contigent attention-getters, etc. etc. All this means that the stuff you actually want to analyze within a trial could be buried among lots of irrelevant data. For example, you might want to only analyze data after stimulus presentation, but have stimuli that starts at a different timepoint on each trial.</p></li>
</ul>

<p>Luckily, eyetrackingR has tools to address both of these problems</p>

<h3>Adding an Area-of-Interest</h3>

<p>Your eyetracking data doesn&#39;t have any columns corresponding to areas of interest. However, it does have columns give you the x,y gaze coordinates. You also have a csv file for each AOI, specifying its boundaries on each type of trial.</p>

<p>In that case, it&#39;s easy to add AOIs to your dataframe:</p>

<pre><code class="r">animate_aoi &lt;- read.csv(&quot;./interest_areas_for_animate_aoi.csv&quot;)

#            Trial Left Top Right Bottom
# 1   FamiliarBird  500 100   900    500
# 2 FamiliarBottle  400 200   800    600
# 3    FamiliarCow  500 300   900    700
# 4    FamiliarDog  300 100   700    500
# 5  FamiliarHorse  500 200   900    600
# 6  FamiliarSpoon  350 300   750    700

data &lt;- add_aoi(data = data, aoi_dataframe = animate_aoi, 
               x_col = &quot;GazeX&quot;, y_col = &quot;GazeY&quot;, 
               aoi_name = &quot;Animate&quot;,
               x_min_col = &quot;Left&quot;, x_max_col = &quot;Right&quot;, y_min_col = &quot;Top&quot;, y_max_col = &quot;Bottom&quot;)
</code></pre>

<p>This can be done for each AOI: just load in a csv file and run the <code>add_aoi</code> function for each.</p>

<p>After using this function, you should probably check that the added AOI column actually indicates that the gaze was ever in the AOI. For example:</p>

<pre><code class="r">table(data$Animate)
</code></pre>

<pre><code>## 
## FALSE  TRUE 
## 49681 82460
</code></pre>

<pre><code class="r">table(is.na(data$Animate)) # if all TRUE, then something went wrong.
</code></pre>

<pre><code>## 
##  FALSE   TRUE 
## 132141  63771
</code></pre>

<p>(Note that you should typically add your AOIs to your dataframe <strong>before</strong> running <code>make_eyetrackingr_data</code>, since that function will check your AOIs.)</p>

<h3>Subsetting into the Time-Window of Interest Across Trials</h3>

<p>eyetrackingR&#39;s <code>subset_by_window</code> has several methods for getting the data you&#39;re interested in. These are powerful because they can be used repeatedly/iteratively to home in on the relevant data. We show this below.</p>

<p>In this example, let&#39;s imagine that our Timestamp doesn&#39;t actually specify the start of the trial&ndash; instead, it specifies the time since the eye-tracker was turned on!</p>

<p>Fortunately, our eye-tracker sends a message when each trial starts (this is not always the same as the very first sample for the trial&ndash; recording often starts a few hundred milliseconds before the trial does). This message can be used to set the zero-point for each trial.</p>

<pre><code class="r">data &lt;- subset_by_window(data, window_start_msg = &quot;TrialStart&quot;, msg_col = &quot;Message&quot;, rezero= TRUE)
</code></pre>

<p>Unfortunately, the eye-tracker didn&#39;t send a message for when the response-window starts. Instead, it added a column that tells you how long after the start of the trial the response-window started. Now that we have rezero&#39;d our data so that 0 = trial-start, this column specifying the time after trial start can be used easily.</p>

<pre><code class="r">response_window &lt;- subset_by_window(data, window_start_col = &quot;ResponseWindowStart&quot;, rezero= FALSE, remove= TRUE)
</code></pre>

<p>Finally, our trials always ended after 21 seconds. So we&#39;ll simply remove data from after this.</p>

<pre><code class="r">response_window &lt;- subset_by_window(response_window, window_end_time = 21000, rezero= FALSE, remove= TRUE)
</code></pre>

<p>In summary, we have subset the data to focus on our time window of interest.</p>

<h2>Dealing with trackloss</h2>

<p>Trackloss occurs when the eye-tracker loses track of the participant&#39;s eyes (e.g., when they turn away or blink) or when it captures their gaze location but with very low validity.</p>

<p>We need to decide which trials to remove (if any) due to very high trackloss. To do so here, we will:</p>

<ul>
<li>Calculate the amount of trackloss in each trial</li>
<li>Remove trials with over 25% trackloss</li>
</ul>

<pre><code class="r"># analyze amount of trackloss by subjects and trials
(trackloss &lt;- trackloss_analysis(data = response_window))
</code></pre>

<pre><code>## # A tibble: 155 x 6
##    ParticipantName Trial Samples TracklossSamples TracklossForTri…
##    &lt;fct&gt;           &lt;fct&gt;   &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1 ANCAT139        Fami…     330              161           0.488 
##  2 ANCAT18         Fami…     330               74           0.224 
##  3 ANCAT18         Fami…     330               43           0.130 
##  4 ANCAT18         Fami…     330              159           0.482 
##  5 ANCAT18         Fami…     330               95           0.288 
##  6 ANCAT18         Fami…     330              165           0.5   
##  7 ANCAT18         Fami…     330               95           0.288 
##  8 ANCAT22         Fami…     330               14           0.0424
##  9 ANCAT22         Fami…     330                8           0.0242
## 10 ANCAT22         Fami…     330               55           0.167 
## # ... with 145 more rows, and 1 more variable:
## #   TracklossForParticipant &lt;dbl&gt;
</code></pre>

<pre><code class="r">response_window_clean &lt;- clean_by_trackloss(data = response_window, trial_prop_thresh = .25)
</code></pre>

<pre><code>## Performing Trackloss Analysis...
</code></pre>

<pre><code>## Will exclude trials whose trackloss proportion is greater than : 0.25
</code></pre>

<pre><code>##  ...removed  33  trials.
</code></pre>

<h2>How much data are we left with?</h2>

<p>After data cleaning, it&#39;s important to assess how much data you are ultimately left with to (a) report along with your findings and, (b) identify any problematic participants who didn&#39;t contribute enough trials from which to reliably estimate their performance.</p>

<h3>Assess mean trackloss for each participant</h3>

<pre><code class="r">trackloss_clean &lt;- trackloss_analysis(data = response_window_clean)

(trackloss_clean_subjects &lt;- unique(trackloss_clean[, c(&#39;ParticipantName&#39;,&#39;TracklossForParticipant&#39;)]))
</code></pre>

<pre><code>## # A tibble: 27 x 2
##    ParticipantName TracklossForParticipant
##    &lt;fct&gt;                             &lt;dbl&gt;
##  1 ANCAT18                          0.177 
##  2 ANCAT22                          0.0588
##  3 ANCAT23                          0.0626
##  4 ANCAT26                          0.0970
##  5 ANCAT39                          0.0379
##  6 ANCAT45                          0.0131
##  7 ANCAT50                          0.0576
##  8 ANCAT53                          0.0485
##  9 ANCAT55                          0.0430
## 10 ANCAT58                          0.0261
## # ... with 17 more rows
</code></pre>

<h3>Summarize samples contributed per trial</h3>

<pre><code class="r"># get mean samples contributed per trials, with SD
mean(1 - trackloss_clean_subjects$TracklossForParticipant)
</code></pre>

<pre><code>## [1] 0.9313075
</code></pre>

<pre><code class="r">sd(1- trackloss_clean_subjects$TracklossForParticipant)
</code></pre>

<pre><code>## [1] 0.05208985
</code></pre>

<h3>Assess number of trials contributed by each participant</h3>

<pre><code class="r"># look at the NumTrials column
(final_summary &lt;- describe_data(response_window_clean, describe_column = &#39;Animate&#39;, group_columns = &#39;ParticipantName&#39;))
</code></pre>

<pre><code>## # A tibble: 27 x 9
##    ParticipantName  Mean    SD LowerQ UpperQ   Min   Max     N NumTrials
##    &lt;fct&gt;           &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;
##  1 ANCAT18         0.169 0.375      0      1     0     1   660         2
##  2 ANCAT22         0.581 0.494      0      1     0     1  1650         5
##  3 ANCAT23         0.780 0.414      0      1     0     1  1980         6
##  4 ANCAT26         0.598 0.490      0      1     0     1  1320         4
##  5 ANCAT39         0.650 0.477      0      1     0     1  1980         6
##  6 ANCAT45         0.679 0.467      0      1     0     1   990         3
##  7 ANCAT50         0.836 0.370      0      1     0     1   990         3
##  8 ANCAT53         0.737 0.441      0      1     0     1   990         3
##  9 ANCAT55         0.745 0.436      0      1     0     1  1650         5
## 10 ANCAT58         0.731 0.443      0      1     0     1  1650         5
## # ... with 17 more rows
</code></pre>

<h3>Summarize number of trials contributed</h3>

<pre><code class="r">mean(final_summary$NumTrials)
</code></pre>

<pre><code>## [1] 4.518519
</code></pre>

<pre><code class="r">sd(final_summary$NumTrials)
</code></pre>

<pre><code>## [1] 1.369176
</code></pre>

<h2>Create additional columns needed for analysis</h2>

<p>Now is the time to make sure that we have all the columns needed for our analyses, because this dataset is going to be shaped and subsetted as we analyze our data and it&#39;s easier to add these columns once then to do it for derivative datasets.</p>

<p>For the present experiment, one thing we want to do is create a &ldquo;Target&rdquo; condition column based on the name of each Trial.</p>

<p>In each trial, the participant was told to look at either an Animate or Inanimate objects. Here we create a column specifying which for each column.</p>

<pre><code class="r">response_window_clean$Target &lt;- as.factor( ifelse(test = grepl(&#39;(Spoon|Bottle)&#39;, response_window_clean$Trial), 
                                       yes = &#39;Inanimate&#39;, 
                                       no  = &#39;Animate&#39;) )
</code></pre>

<p>Our dataset is now ready for analysis!</p>

</body>

</html>
